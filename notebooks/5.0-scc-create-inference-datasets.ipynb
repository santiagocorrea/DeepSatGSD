{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb05fba9-c397-4f85-ad94-1e75b52e1379",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/scorreacardo_umass_edu/miniconda3/envs/urbano2/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import rasterio\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import ToTensor, Normalize\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataset import Subset\n",
    "from sklearn.metrics import classification_report\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pdb\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acdd8f73-0a63-4d46-9f89-5427849c4182",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_tiles = \"gypsum/eguide/projects/scorreacardo/urbano/data/worldpop_centered/processed/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ab9e52-154b-472f-bc07-277eb5c0badb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the root directory containing the satellite image tiles\n",
    "root_dir = \"/gypsum/eguide/projects/scorreacardo/urbano/data/worldpop_centered/processed/\"\n",
    "\n",
    "# Define the output directory for the chips\n",
    "output_dir = \"/work/scorreacardo_umass_edu/DeepSatGSD/data/processed/inference\"\n",
    "\n",
    "# Define the desired chip size\n",
    "chip_size = 256\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Initialize a list to store the chip filenames and dates\n",
    "chip_filenames = []\n",
    "chip_dates = []\n",
    "\n",
    "# Walk through the root directory and its subdirectories\n",
    "for root, dirs, files in os.walk(root_dir):\n",
    "    # Iterate over the files in the current directory\n",
    "    for file in tqdm(files):\n",
    "        # Check if the file is a PNG image\n",
    "        if file.lower().endswith(\".png\"):\n",
    "            # Get the full path of the image file\n",
    "            image_path = os.path.join(root, file)\n",
    "            \n",
    "            # Open the image file\n",
    "            image = Image.open(image_path)\n",
    "            \n",
    "            # Get the image size\n",
    "            image_width, image_height = image.size\n",
    "            \n",
    "            # Iterate over the image in a sliding window fashion to extract chips\n",
    "            for y in range(0, image_height - chip_size + 1, chip_size):\n",
    "                for x in range(0, image_width - chip_size + 1, chip_size):\n",
    "                    # Extract the chip from the image\n",
    "                    chip = image.crop((x, y, x + chip_size, y + chip_size))\n",
    "                    \n",
    "                    # Get the date from the filename\n",
    "                    year = file.split(\"_\")[0]\n",
    "                    month = file.split(\"_\")[1]\n",
    "                    day = file.split(\"_\")[2]\n",
    "                    tilename = file.split(\"_\")[4]\n",
    "                    \n",
    "                    # Create a unique filename for the chip\n",
    "                    chip_filename = f\"{year}_{month}_{year}_{tilename}_{x}_{y}_.tif\"\n",
    "                    \n",
    "                    # Save the chip as a TIFF image\n",
    "                    chip_path = os.path.join(output_dir, chip_filename)\n",
    "                    chip.save(chip_path, format=\"TIFF\")\n",
    "                    \n",
    "                    # Append the chip filename and date to the lists\n",
    "                    chip_filenames.append(chip_filename)\n",
    "                    chip_dates.append(f\"{year}/{month}/{day}\")\n",
    "\n",
    "# Print the list of chip filenames and dates\n",
    "count=0\n",
    "for filename, date in zip(chip_filenames, chip_dates):\n",
    "    count += 1\n",
    "    if count % 500 == 0:\n",
    "        print(f\"Chip Filename: {filename}, Date: {date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3da98a9c-fc54-45bc-97ec-40a53d21ec32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's create the inference class:\n",
    "class InferenceDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.class_dir = None\n",
    "        self.transform = transform\n",
    "        self.classes = None\n",
    "        self.filepaths = []\n",
    "        self.dates = []\n",
    "        \n",
    "        class_dir = \"/work/scorreacardo_umass_edu/DeepSatGSD/data/processed/random_synthetic\"\n",
    "        self.classes = sorted([filename for filename in os.listdir(class_dir) if filename.startswith(\"GSD\")], \n",
    "                              key=lambda x: int(x.split('_')[1][:-2]))\n",
    "        \n",
    "        file_list = [f for f in os.listdir(root_dir)]\n",
    "        sampled_files = random.sample(file_list, k=int(len(file_list) * 0.20))\n",
    "                \n",
    "        for filename in sampled_files:\n",
    "            filepath = os.path.join(root_dir, filename)\n",
    "            self.filepaths.append(filepath)\n",
    "            year = filename.split(\"_\")[0]\n",
    "            month = filename.split(\"_\")[1]\n",
    "            self.dates.append(f\"{year}/{month}\")\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filepaths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        filepath = self.filepaths[index]\n",
    "        date = self.dates[index]\n",
    "\n",
    "        with rasterio.open(filepath, 'r') as img:\n",
    "            image = img.read()\n",
    "            image = image[:3, :, :]\n",
    "            image = image.transpose(1, 2, 0)\n",
    "        if self.transform:\n",
    "            image = self.transform(image).float()\n",
    "\n",
    "        return image, date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b51afbee-0de1-4c74-88b8-b1854a88edb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the image transformations\n",
    "transform = torchvision.transforms.Compose([\n",
    "    ToTensor(),\n",
    "    Normalize([0.46619912981987, 0.4138015806674957, 0.2945951819419861], \n",
    "              [0.19115719199180603, 0.1479424238204956, 0.13974712789058685])  # Normalize image tensors\n",
    "])\n",
    "batch_size = 16\n",
    "root_dir = \"/work/scorreacardo_umass_edu/DeepSatGSD/data/processed/inference\"\n",
    "inference_dataset = InferenceDataset(root_dir, transform=transform)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17a62fa2-8dec-4b9a-88dc-f34108a8266b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping = {dataloader_class: dataset_class for dataloader_class, dataset_class in zip(dataloader_classes, dataset.classes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b12208-53ba-4476-9388-867b6381c3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the same model architecture\n",
    "import torchvision.models as models\n",
    "\n",
    "model = models.resnet18(pretrained=False)\n",
    "num_classes = len(inference_dataset.classes)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "# Load the saved model state dictionary\n",
    "model.load_state_dict(torch.load('/work/scorreacardo_umass_edu/DeepSatGSD/models/trained_model_gsd_resnet18_epochs_3_training_40_perc.pt'))\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Now you can use the model for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f523835e-1915-43fc-8220-3ca504010b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1505/1505 [15:00<00:00,  1.67it/s]\n"
     ]
    }
   ],
   "source": [
    "# Move the model to the appropriate device (e.g., GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "dates_results = []\n",
    "predicted_results = []\n",
    "\n",
    "# Perform inference\n",
    "with torch.no_grad():\n",
    "    for inputs, dates in tqdm(inference_loader):\n",
    "        inputs = inputs.to(device)  # Move inputs to the appropriate device\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        dates_results += dates\n",
    "        predicted_results += predicted.tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "urbano2",
   "language": "python",
   "name": "urbano2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
