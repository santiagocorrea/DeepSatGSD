{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db30c0a3-e88e-455c-8d86-7926916b2d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/scorreacardo_umass_edu/miniconda3/envs/urbano2/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import ToTensor, Normalize\n",
    "from PIL import Image\n",
    "import pdb\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67721ac6-87a1-46b4-afe7-dd0cbe7d06b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map = {0:'GSD_50cm',\n",
    " 1:'GSD_65cm',\n",
    " 2:'GSD_80cm',\n",
    " 3:'GSD_100cm',\n",
    " 4:'GSD_124cm',\n",
    " 5:'GSD_150cm',\n",
    " 6:'GSD_175cm',\n",
    " 7:'GSD_200cm',\n",
    " 8:'GSD_250cm',\n",
    " 9:'GSD_300cm'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "085f473c-ec34-405a-b3dd-7471707fc456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3381/3381 [33:31<00:00,  1.68it/s] \n"
     ]
    }
   ],
   "source": [
    "# Move the model to the appropriate device (e.g., GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "# Create an instance of the same model architecture\n",
    "model = models.resnet18(pretrained=False)\n",
    "num_classes = 10\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "# Load the saved model state dictionary\n",
    "model.load_state_dict(torch.load('/work/scorreacardo_umass_edu/DeepSatGSD/models/trained_model_gsd_resnet18_epochs_3_training_40_perc.pt'))\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "# Define the transformation to be applied to the images\n",
    "transform = torchvision.transforms.Compose([\n",
    "    ToTensor(),\n",
    " \n",
    "    Normalize([0.46619912981987, 0.4138015806674957, 0.2945951819419861], \n",
    "              [0.19115719199180603, 0.1479424238204956, 0.13974712789058685]) \n",
    "])\n",
    "# Path to the folder containing the images for inference\n",
    "inference_folder = '/gypsum/eguide/projects/scorreacardo/urbano/data/processed/train_img'\n",
    "inference_folder_mask = '/gypsum/eguide/projects/scorreacardo/urbano/data/processed/train_masks'\n",
    "\n",
    "# Path to the folder where the images will be copied based on the predicted class\n",
    "output_folder = '/work/scorreacardo_umass_edu/DeepSatGSD/data/processed/inferece_gep_classified'\n",
    "\n",
    "# Iterate over the images in the inference folder\n",
    "for image_name in tqdm(os.listdir(inference_folder)[7289+16876:]):\n",
    "    image_path = os.path.join(inference_folder, image_name)\n",
    "    mask_path = os.path.join(inference_folder_mask, image_name)\n",
    "\n",
    "    # Load and preprocess the image\n",
    "    image = np.asarray(Image.open(image_path))\n",
    "    mask = np.asarray(Image.open(mask_path))\n",
    "    image = image[:, :, :3]\n",
    "    mask = mask[:, :, :3]\n",
    "    image = transform(image).float()\n",
    "    image = image.unsqueeze(0)  # Add batch dimension\n",
    "    #image = image.to(device, dtype=torch.float32)  # Move the image to GPU\n",
    "    \n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "    _, predicted_class = torch.max(output, 1)\n",
    "    \n",
    "    predicted_class = predicted_class.item()\n",
    "\n",
    "    # Create the folder if it doesn't exist\n",
    "    class_folder = os.path.join(output_folder, class_map[predicted_class])\n",
    "    img_folder = os.path.join(class_folder, 'imgs')\n",
    "    mask_folder = os.path.join(class_folder, 'masks')\n",
    "    os.makedirs(class_folder, exist_ok=True)\n",
    "    os.makedirs(img_folder, exist_ok=True)\n",
    "    os.makedirs(mask_folder, exist_ok=True)\n",
    "\n",
    "    # Copy the image to the respective class folder\n",
    "    shutil.copy(image_path, img_folder)\n",
    "    # Copy the mask to the respective class folder\n",
    "    shutil.copy(mask_path, mask_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc98c16d-c1f9-45ba-a833-ff73c837f1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Set the paths to your folders\n",
    "imgs_folder = '/work/scorreacardo_umass_edu/DeepSatGSD/data/processed/inferece_gep_classified/GSD_65cm/imgs'\n",
    "masks_folder = '/work/scorreacardo_umass_edu/DeepSatGSD/data/processed/inferece_gep_classified/GSD_65cm/masks'\n",
    "train_folder = '/work/scorreacardo_umass_edu/DeepSatGSD/data/processed/inferece_gep_classified/GSD_65cm/train'\n",
    "valid_folder = '/work/scorreacardo_umass_edu/DeepSatGSD/data/processed/inferece_gep_classified/GSD_65cm/valid'\n",
    "train_imgs_folder = os.path.join(train_folder, 'imgs')\n",
    "train_masks_folder = os.path.join(train_folder, 'masks')\n",
    "valid_imgs_folder = os.path.join(valid_folder, 'imgs')\n",
    "valid_masks_folder = os.path.join(valid_folder, 'masks')\n",
    "\n",
    "# Create the train and valid folders if they don't exist\n",
    "os.makedirs(train_imgs_folder, exist_ok=True)\n",
    "os.makedirs(train_masks_folder, exist_ok=True)\n",
    "os.makedirs(valid_imgs_folder, exist_ok=True)\n",
    "os.makedirs(valid_masks_folder, exist_ok=True)\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Get the list of image file names in the imgs folder\n",
    "all_files = os.listdir(imgs_folder)\n",
    "\n",
    "# Filter out non-image files based on file extensions\n",
    "image_files = [file for file in all_files if os.path.splitext(file)[1].lower() in ['.jpg', '.jpeg', '.png']]\n",
    "\n",
    "\n",
    "# Shuffle the list of image file names\n",
    "random.shuffle(image_files)\n",
    "\n",
    "# Define the desired ratio of training to validation images\n",
    "train_ratio = 0.8  # 80% for training, 20% for validation\n",
    "\n",
    "# Calculate the number of training images based on the ratio\n",
    "num_train = int(len(image_files) * train_ratio)\n",
    "\n",
    "# Split the image and mask files into training and validation sets\n",
    "train_images = image_files[:num_train]\n",
    "valid_images = image_files[num_train:]\n",
    "\n",
    "# Copy the training images and masks to the train folder\n",
    "for image_file in train_images:\n",
    "    img_src = os.path.join(imgs_folder, image_file)\n",
    "    mask_src = os.path.join(masks_folder, image_file)\n",
    "    shutil.copy(img_src, train_imgs_folder)\n",
    "    shutil.copy(mask_src, train_masks_folder)\n",
    "\n",
    "# Copy the validation images and masks to the valid folder\n",
    "for image_file in valid_images:\n",
    "    img_src = os.path.join(imgs_folder, image_file)\n",
    "    mask_src = os.path.join(masks_folder, image_file)\n",
    "    shutil.copy(img_src, valid_imgs_folder)\n",
    "    shutil.copy(mask_src, valid_masks_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9ba1e5-96ae-4de3-a23e-863c287092f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from skimage import io\n",
    "\n",
    "def check_images(folder_path):\n",
    "    error_images = []\n",
    "\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        try:\n",
    "            image = io.imread(file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading image '{file_name}': {e}\")\n",
    "            error_images.append(file_name)\n",
    "\n",
    "    return error_images\n",
    "\n",
    "# Replace 'your_folder_path' with the actual path to your folder containing images\n",
    "folder_with_images = '/work/scorreacardo_umass_edu/DeepSatGSD/data/processed/inferece_gep_classified/GSD_65cm/valid/imgs'\n",
    "images_with_issues = check_images(folder_with_images)\n",
    "\n",
    "if not images_with_issues:\n",
    "    print(\"All images were read successfully.\")\n",
    "else:\n",
    "    print(\"The following images had issues reading:\")\n",
    "    for img in images_with_issues:\n",
    "        print(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1420236c-ae99-41ff-ac5e-c0419b047611",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "urbano2",
   "language": "python",
   "name": "urbano2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
