{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9473074-e1d9-42f2-8c97-28a200aeddf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31178366-f88c-4529-871b-aebaf23cbfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chips(image_path, output_dir):\n",
    "    with rasterio.open(image_path) as dataset:\n",
    "        height, width = dataset.shape\n",
    "\n",
    "        for row in range(0, height, chip_size):\n",
    "            for col in range(0, width, chip_size):\n",
    "                chip_window = Window(col, row, chip_size, chip_size)\n",
    "                chip = dataset.read(window=chip_window)\n",
    "\n",
    "                chip_filename = f\"row{row}_col{col}_\" + os.path.splitext(os.path.basename(image_path))[0] + \".tif\"\n",
    "                chip_filepath = os.path.join(output_dir, chip_filename)\n",
    "\n",
    "                with rasterio.open(\n",
    "                    chip_filepath,\n",
    "                    'w',\n",
    "                    driver='GTiff',\n",
    "                    height=chip_size,\n",
    "                    width=chip_size,\n",
    "                    count=dataset.count,\n",
    "                    dtype=dataset.dtypes[0],\n",
    "                    crs=dataset.crs,\n",
    "                    transform=rasterio.windows.transform(chip_window, dataset.transform)\n",
    "                ) as chip_dataset:\n",
    "                    chip_dataset.write(chip, indexes=list(range(1, dataset.count + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a046f26-94c1-4cd8-b3ea-85bc1c0d05cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('AOP_AF17_Q317_V0_502_308_133_9_R3C5_2017-03-14_WV02_resampled_image_1.5m',\n",
       " '.tif')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path ='work/scorreacardo_umass_edu/DeepSatGSD/data/interim/GSD_150cm/AOP_AF17_Q317_V0_502_308_133_9_R3C5_2017-03-14_WV02_resampled_image_1.5m.tif'\n",
    "os.path.splitext(os.path.basename(image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59856415-3987-4ad5-89ce-90c26cbab045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the paths to your original data directory and the destination dataset directory\n",
    "original_data_dir = \"/work/scorreacardo_umass_edu/DeepSatGSD/data/interim\"\n",
    "dataset_dir = \"/work/scorreacardo_umass_edu/DeepSatGSD/data/processed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d75dfba-678f-4908-b68a-55f5f9d50829",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors = ['GSD_50cm', 'GSD_65cm', 'GSD_80cm', 'GSD_100cm',\n",
    "          'GSD_124cm', 'GSD_150cm', 'GSD_175cm', 'GSD_200cm', \n",
    "           'GSD_250cm', 'GSD_300cm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9d25b19-441c-4236-9131-e145cd12eb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the train, validation, and test ratios\n",
    "train_ratio = 0.7\n",
    "validation_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "\n",
    "# Set the chip size\n",
    "chip_size = 256\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94056703-ad7b-4beb-a2d3-362c71a5ed0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the directories for train, validation, and test sets\n",
    "train_dir = os.path.join(dataset_dir, 'train')\n",
    "validation_dir = os.path.join(dataset_dir, 'validation')\n",
    "test_dir = os.path.join(dataset_dir, 'test')\n",
    "\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(validation_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e12af850-cf5f-4b2c-bf81-fe9c85c32369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensor name: GSD_200cm\n",
      "size of train images: 21\n",
      "size of validation images: 4\n",
      "size of test images: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [25:00<00:00, 71.46s/it] \n",
      "100%|██████████| 4/4 [04:03<00:00, 60.90s/it]\n",
      "100%|██████████| 5/5 [07:27<00:00, 89.45s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensor name: GSD_250cm\n",
      "size of train images: 21\n",
      "size of validation images: 4\n",
      "size of test images: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [33:58<00:00, 97.07s/it]  \n",
      "100%|██████████| 4/4 [01:39<00:00, 24.82s/it]\n",
      "100%|██████████| 5/5 [04:18<00:00, 51.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensor name: GSD_300cm\n",
      "size of train images: 21\n",
      "size of validation images: 4\n",
      "size of test images: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [38:37<00:00, 110.35s/it]\n",
      "100%|██████████| 4/4 [02:14<00:00, 33.54s/it]\n",
      "100%|██████████| 5/5 [02:02<00:00, 24.48s/it]\n"
     ]
    }
   ],
   "source": [
    "# Loop through each sensor and distribute the images across the sets\n",
    "for sensor_name in sensors:\n",
    "    print(f\"sensor name: {sensor_name}\")\n",
    "    sensor_images = [filename for filename in os.listdir(os.path.join(original_data_dir, sensor_name))]\n",
    "    random.shuffle(sensor_images)\n",
    "\n",
    "    train_count = int(len(sensor_images) * train_ratio)\n",
    "    validation_count = int(len(sensor_images) * validation_ratio)\n",
    "    test_count = len(sensor_images) - train_count - validation_count\n",
    "\n",
    "    train_images = sensor_images[:train_count]\n",
    "    print(f\"size of train images: {len(train_images)}\")\n",
    "    validation_images = sensor_images[train_count:train_count + validation_count]\n",
    "    print(f\"size of validation images: {len(validation_images)}\")\n",
    "    test_images = sensor_images[train_count + validation_count:]\n",
    "    print(f\"size of test images: {len(test_images)}\")\n",
    "    \n",
    "    # Create the sub-directories for train, validation, and test sets for each sensor\n",
    "    sensor_train_dir = os.path.join(train_dir, sensor_name)\n",
    "    sensor_validation_dir = os.path.join(validation_dir, sensor_name)\n",
    "    sensor_test_dir = os.path.join(test_dir, sensor_name)\n",
    "    \n",
    "    os.makedirs(sensor_train_dir, exist_ok=True)\n",
    "    os.makedirs(sensor_validation_dir, exist_ok=True)\n",
    "    os.makedirs(sensor_test_dir, exist_ok=True)\n",
    "    \n",
    "    # Move the images to their respective directories and create chips\n",
    "    for image in tqdm(train_images):\n",
    "        src = os.path.join(original_data_dir + f\"/{sensor_name}\", image)\n",
    "        dst = os.path.join(sensor_train_dir, image)\n",
    "        shutil.copyfile(src, dst)\n",
    "        create_chips(dst, sensor_train_dir)\n",
    "\n",
    "    for image in tqdm(validation_images):\n",
    "        src = os.path.join(original_data_dir + f\"/{sensor_name}\", image)\n",
    "        dst = os.path.join(sensor_validation_dir, image)\n",
    "        shutil.copyfile(src, dst)\n",
    "        create_chips(dst, sensor_validation_dir)\n",
    "\n",
    "    for image in tqdm(test_images):\n",
    "        src = os.path.join(original_data_dir + f\"/{sensor_name}\", image)\n",
    "        dst = os.path.join(sensor_test_dir, image)\n",
    "        shutil.copyfile(src, dst)\n",
    "        create_chips(dst, sensor_test_dir)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a069b888-6e8a-4d69-9acb-219d7b0c04d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of training data for GSD_250cm: 73306 chips of 256x256\n"
     ]
    }
   ],
   "source": [
    "test_path = \"/work/scorreacardo_umass_edu/DeepSatGSD/data/processed/train/GSD_300cm\"\n",
    "size = len([f for f in os.listdir(test_path) if f.startswith(\"row\")])\n",
    "print(f\"size of training data for GSD_250cm: {size} chips of 256x256\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e9f8b5-f597-481f-b280-b2c8c7b420fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "urbano2",
   "language": "python",
   "name": "urbano2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
