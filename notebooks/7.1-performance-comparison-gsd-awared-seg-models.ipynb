{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f09f7c7-bbda-4847-b5b5-9f51bdd08485",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/scorreacardo_umass_edu/miniconda3/envs/urbano2/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import rasterio\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import ToTensor, Normalize\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataset import Subset\n",
    "from sklearn.metrics import classification_report\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pdb\n",
    "from collections import Counter\n",
    "import segmentation_models_pytorch as smp\n",
    "import albumentations as albu\n",
    "from skimage.io import imread\n",
    "import pandas as pd\n",
    "import cv2\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6437ac85-2f95-412d-b720-0e92f437b5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map = {0:'GSD_50cm',\n",
    " 1:'GSD_65cm',\n",
    " 2:'GSD_80cm',\n",
    " 3:'GSD_100cm',\n",
    " 4:'GSD_124cm',\n",
    " 5:'GSD_150cm',\n",
    " 6:'GSD_175cm',\n",
    " 7:'GSD_200cm',\n",
    " 8:'GSD_250cm',\n",
    " 9:'GSD_300cm'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2aca620-45ed-4660-8b45-7ed15e9d3100",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(gsd, aug=False):\n",
    "    if aug:\n",
    "        exp_dic = {\n",
    "            '50cm': 'exp2',\n",
    "            '65cm': 'exp4', \n",
    "            '80cm': 'exp6'\n",
    "        }\n",
    "    else:\n",
    "        exp_dic = {\n",
    "            '50cm': 'exp1',\n",
    "            '65cm': 'exp3', \n",
    "            '80cm': 'exp5'\n",
    "        }\n",
    "        \n",
    "    model = torch.load(f'/work/scorreacardo_umass_edu/DeepSatGSD/models/segmentation_{exp_dic[gsd]}_{gsd}_best_model.pth')\n",
    "    return model\n",
    "\n",
    "def to_tensor(x, **kwargs):\n",
    "    return x.transpose(2, 0, 1).astype('float32')\n",
    "\n",
    "def get_preprocessing(preprocessing_fn):\n",
    "    \"\"\"Construct preprocessing transform\n",
    "    \n",
    "    Args:\n",
    "        preprocessing_fn (callbale): data normalization function \n",
    "            (can be specific for each pretrained neural network)\n",
    "    Return:\n",
    "        transform: albumentations.Compose\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    _transform = [\n",
    "        albu.Lambda(image=preprocessing_fn),\n",
    "        albu.Lambda(image=to_tensor, mask=to_tensor),\n",
    "    ]\n",
    "    return albu.Compose(_transform)\n",
    "\n",
    "def sigmoid(X):\n",
    "    return 1/(1+np.exp(-X))\n",
    "\n",
    "def iou(pr_mask, gt_mask):\n",
    "    pr_mask_area = np.count_nonzero(pr_mask)\n",
    "    gt_mask_area = np.count_nonzero(gt_mask)\n",
    "    intersection = np.count_nonzero(np.logical_and(pr_mask, gt_mask))\n",
    "    if pr_mask_area + gt_mask_area - intersection == 0:\n",
    "        return None\n",
    "    iou = intersection/(pr_mask_area + gt_mask_area - intersection)\n",
    "    return iou\n",
    "\n",
    "def se(pr_mask, gt_mask):\n",
    "    pr_contours, _ = cv2.findContours(pr_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    gt_contours, _ = cv2.findContours(gt_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    sq_error = (len(pr_contours) - len(gt_contours))**2\n",
    "    return sq_error\n",
    "\n",
    "def perc_error(pr_mask, gt_mask):\n",
    "    pr_contours, _ = cv2.findContours(pr_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    gt_contours, _ = cv2.findContours(gt_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if len(gt_contours) == 0:\n",
    "        return None\n",
    "    perc_error = (len(pr_contours) - len(gt_contours))/len(gt_contours)\n",
    "    return perc_error*100\n",
    "\n",
    "def perc_area(pr_mask, gt_mask):\n",
    "    #area as percentage of total area\n",
    "    pr_pixels = cv2.countNonZero(pr_mask)\n",
    "    gt_pixels = cv2.countNonZero(gt_mask)\n",
    "    if gt_pixels == 0:\n",
    "        return None\n",
    "    return (pr_pixels/gt_pixels)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0940c9f1-9bb6-4688-a21c-8a3710f47692",
   "metadata": {},
   "outputs": [],
   "source": [
    "gsd = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4648e587-1cad-464c-85fc-cc7f17351aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_counter = []\n",
    "res_dic = {\n",
    "    'img_name': [],\n",
    "    'class_gsd':[],\n",
    "    'iou': [],\n",
    "    'se': [],\n",
    "    'perc_error': [],\n",
    "    'perc_area': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6be10011-3043-40c2-9eec-aa52f1d4bd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the folder containing the images for inference\n",
    "inference_folder = f'/work/scorreacardo_umass_edu/DeepSatGSD/data/processed/inferece_gep_classified/{class_map[gsd]}/valid/imgs'\n",
    "inference_folder_mask = f'/work/scorreacardo_umass_edu/DeepSatGSD/data/processed/inferece_gep_classified/{class_map[gsd]}/valid/masks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c5ddbc90-1250-4eab-a70a-c198f9c55273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GSD_80cm'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_map[gsd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4376464a-c34f-4652-8e85-07203eb2d8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2546/2546 [05:09<00:00,  8.23it/s]\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the images in the inference folder\n",
    "for image_name in tqdm(os.listdir(inference_folder)):\n",
    "    image_path = os.path.join(inference_folder, image_name)\n",
    "    mask_path = os.path.join(inference_folder_mask, image_name)\n",
    "\n",
    "    res_dic['img_name'].append(image_name)\n",
    "    res_dic['class_gsd'].append(class_map[gsd])\n",
    "    \n",
    "    preprocessing_fn = smp.encoders.get_preprocessing_fn(\"resnet34\", \"imagenet\")\n",
    "    seg_model = get_model(class_map[gsd].split(\"_\")[1], aug=True)\n",
    "    seg_model.eval()\n",
    "    seg_transform =  albu.Compose([\n",
    "        albu.Lambda(image=preprocessing_fn),\n",
    "        albu.Lambda(image=to_tensor, mask=to_tensor),\n",
    "    ])\n",
    "\n",
    "    image = imread(image_path)[:,:,:3].astype('float32')/255\n",
    "    mask = imread(mask_path, as_gray=True)[:,:,np.newaxis]\n",
    "    \n",
    "    image_transformed = seg_transform(image=image, mask=mask)['image']\n",
    "    mask_transformed = seg_transform(image=image, mask=mask)['mask']\n",
    "    \n",
    "    gt_mask_test = mask_transformed.squeeze()\n",
    "    x_tensor_test = torch.from_numpy(image_transformed).to('cuda').unsqueeze(0)\n",
    "      # Perform inference\n",
    "    with torch.no_grad():\n",
    "        pr_mask_test = seg_model.predict(x_tensor_test)\n",
    "    pr_mask_test = (pr_mask_test.squeeze().cpu().numpy().round())\n",
    "\n",
    "    pr_mask_test_th = sigmoid(pr_mask_test)\n",
    "    pr_mask_test_th = pr_mask_test_th > 0.5\n",
    "    pr_mask_test_th = np.uint8(np.multiply(pr_mask_test_th, 255))\n",
    "\n",
    "    gt_mask_test = np.uint8(gt_mask_test)\n",
    "    #calculating IoU per patch:\n",
    "    iou_score = iou(pr_mask_test_th, gt_mask_test)\n",
    "    se_score = se(pr_mask_test_th, gt_mask_test)\n",
    "    pe_score = perc_error(pr_mask_test_th, gt_mask_test)\n",
    "    pa_score = perc_area(pr_mask_test_th, gt_mask_test)\n",
    "    res_dic['iou'].append(iou_score)\n",
    "    res_dic['se'].append(se_score)\n",
    "    res_dic['perc_error'].append(pe_score)\n",
    "    res_dic['perc_area'].append(pa_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "urbano2",
   "language": "python",
   "name": "urbano2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
