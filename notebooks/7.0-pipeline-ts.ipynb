{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "260ef196-1b5e-4cc8-b87c-ce4d2c1b4818",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/scorreacardo_umass_edu/miniconda3/envs/urbano2/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import rasterio\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import ToTensor, Normalize\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataset import Subset\n",
    "from sklearn.metrics import classification_report\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pdb\n",
    "from collections import Counter\n",
    "import segmentation_models_pytorch as smp\n",
    "import albumentations as albu\n",
    "from skimage.io import imread\n",
    "import pandas as pd\n",
    "import cv2\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cce69744-8496-4b88-b213-d8fc424e899b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_tiles = \"/gypsum/eguide/projects/scorreacardo/urbano/data/ts_predict_sample/kenya/02356b68-aa6f-4e4c-8a42-d225b2b562d4/images\"\n",
    "path_to_masks = \"/gypsum/eguide/projects/scorreacardo/urbano/data/ts_predict_sample/kenya/02356b68-aa6f-4e4c-8a42-d225b2b562d4/labels_mask\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7e0068d-61c7-4f75-9cf2-d32b99695e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:16<00:00,  4.05s/it]\n"
     ]
    }
   ],
   "source": [
    "# Define the root directory containing the satellite image tiles\n",
    "root_dir_imgs = \"/gypsum/eguide/projects/scorreacardo/urbano/data/ts_predict_sample/kenya/02356b68-aa6f-4e4c-8a42-d225b2b562d4/images\"\n",
    "root_dir_masks = \"/gypsum/eguide/projects/scorreacardo/urbano/data/ts_predict_sample/kenya/02356b68-aa6f-4e4c-8a42-d225b2b562d4/labels_mask\"\n",
    "# Define the output directory for the chips\n",
    "output_dir_imgs = \"/work/scorreacardo_umass_edu/DeepSatGSD/data/processed/inference_ts/imgs\"\n",
    "output_dir_masks = \"/work/scorreacardo_umass_edu/DeepSatGSD/data/processed/inference_ts/masks\"\n",
    "# Define the desired chip size\n",
    "chip_size = 256\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_dir_imgs):\n",
    "    os.makedirs(output_dir_imgs)\n",
    "    \n",
    "if not os.path.exists(output_dir_masks):\n",
    "    os.makedirs(output_dir_masks)\n",
    "\n",
    "\n",
    "# Initialize a list to store the chip filenames and dates\n",
    "chip_filenames = []\n",
    "chip_dates = []\n",
    "\n",
    "for image_name in tqdm(os.listdir(root_dir_imgs)):\n",
    "\n",
    "# # Walk through the root directory and its subdirectories\n",
    "# for root, dirs, files in os.walk(root_dir):\n",
    "    # Iterate over the files in the current directory\n",
    "#for file in tqdm(files):\n",
    "    # Check if the file is a PNG image\n",
    "    if image_name.lower().endswith(\".jpg\"):\n",
    "        # Get the full path of the image file\n",
    "        image_path = os.path.join(root_dir_imgs, image_name)\n",
    "        mask_path = os.path.join(root_dir_masks, image_name[:-4] + \".png\")\n",
    "\n",
    "        # Open the image file\n",
    "        image = Image.open(image_path)\n",
    "        mask = Image.open(mask_path)\n",
    "\n",
    "        # Get the image size\n",
    "        image_width, image_height = image.size\n",
    "\n",
    "        # Iterate over the image in a sliding window fashion to extract chips\n",
    "        for y in range(0, image_height - chip_size + 1, chip_size):\n",
    "            for x in range(0, image_width - chip_size + 1, chip_size):\n",
    "                # Extract the chip from the image\n",
    "                chip_img = image.crop((x, y, x + chip_size, y + chip_size))\n",
    "                chip_mask = mask.crop((x, y, x + chip_size, y + chip_size))\n",
    "\n",
    "                # Get the date from the filename\n",
    "                year = image_name.split(\"_\")[0]\n",
    "                month = image_name.split(\"_\")[1]\n",
    "                day = image_name.split(\"_\")[2]\n",
    "                tilename = image_name.split(\"_\")[4]\n",
    "\n",
    "                # Create a unique filename for the chip\n",
    "                chip_img_filename = f\"{year}_{month}_{day}_{tilename}_{x}_{y}.png\"\n",
    "                chip_mask_filename = f\"{year}_{month}_{day}_{tilename}_{x}_{y}.png\"\n",
    "                \n",
    "\n",
    "                # Save the chip\n",
    "                chip_path_imgs = os.path.join(output_dir_imgs, chip_img_filename)\n",
    "                chip_img.save(chip_path_imgs)\n",
    "                \n",
    "                # Save the chip\n",
    "                chip_path_masks = os.path.join(output_dir_masks, chip_mask_filename)\n",
    "                chip_mask.save(chip_path_masks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5344f1a2-86ce-496f-a7ac-accbb1d4b18c",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bb69c55-8dee-43d1-a461-5c070a8315a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map = {0:'GSD_50cm',\n",
    " 1:'GSD_65cm',\n",
    " 2:'GSD_80cm',\n",
    " 3:'GSD_100cm',\n",
    " 4:'GSD_124cm',\n",
    " 5:'GSD_150cm',\n",
    " 6:'GSD_175cm',\n",
    " 7:'GSD_200cm',\n",
    " 8:'GSD_250cm',\n",
    " 9:'GSD_300cm'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "919dd1cd-35ee-459a-8c91-f9ba0f820071",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(gsd, aug=False):\n",
    "    if aug:\n",
    "        exp_dic = {\n",
    "            '50cm': 'exp2',\n",
    "            '65cm': 'exp4', \n",
    "            '80cm': 'exp6'\n",
    "        }\n",
    "    else:\n",
    "        exp_dic = {\n",
    "            '50cm': 'exp1',\n",
    "            '65cm': 'exp3', \n",
    "            '80cm': 'exp5'\n",
    "        }\n",
    "        \n",
    "    model = torch.load(f'/work/scorreacardo_umass_edu/DeepSatGSD/models/segmentation_{exp_dic[gsd]}_{gsd}_best_model.pth')\n",
    "    return model\n",
    "\n",
    "def to_tensor(x, **kwargs):\n",
    "    return x.transpose(2, 0, 1).astype('float32')\n",
    "\n",
    "def get_preprocessing(preprocessing_fn):\n",
    "    \"\"\"Construct preprocessing transform\n",
    "    \n",
    "    Args:\n",
    "        preprocessing_fn (callbale): data normalization function \n",
    "            (can be specific for each pretrained neural network)\n",
    "    Return:\n",
    "        transform: albumentations.Compose\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    _transform = [\n",
    "        albu.Lambda(image=preprocessing_fn),\n",
    "        albu.Lambda(image=to_tensor, mask=to_tensor),\n",
    "    ]\n",
    "    return albu.Compose(_transform)\n",
    "\n",
    "def sigmoid(X):\n",
    "    return 1/(1+np.exp(-X))\n",
    "\n",
    "def iou(pr_mask, gt_mask):\n",
    "    pr_mask_area = np.count_nonzero(pr_mask)\n",
    "    gt_mask_area = np.count_nonzero(gt_mask)\n",
    "    intersection = np.count_nonzero(np.logical_and(pr_mask, gt_mask))\n",
    "    if pr_mask_area + gt_mask_area - intersection == 0:\n",
    "        return None\n",
    "    iou = intersection/(pr_mask_area + gt_mask_area - intersection)\n",
    "    return iou\n",
    "\n",
    "def se(pr_mask, gt_mask):\n",
    "    pr_contours, _ = cv2.findContours(pr_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    gt_contours, _ = cv2.findContours(gt_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    sq_error = (len(pr_contours) - len(gt_contours))**2\n",
    "    return sq_error\n",
    "\n",
    "def perc_error(pr_mask, gt_mask):\n",
    "    pr_contours, _ = cv2.findContours(pr_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    gt_contours, _ = cv2.findContours(gt_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if len(gt_contours) == 0:\n",
    "        return None\n",
    "    perc_error = (len(pr_contours) - len(gt_contours))/len(gt_contours)\n",
    "    return perc_error*100\n",
    "\n",
    "def perc_area(pr_mask, gt_mask):\n",
    "    #area as percentage of total area\n",
    "    pr_pixels = cv2.countNonZero(pr_mask)\n",
    "    gt_pixels = cv2.countNonZero(gt_mask)\n",
    "    if gt_pixels == 0:\n",
    "        return None\n",
    "    return (pr_pixels/gt_pixels)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a958fda-6aaf-4850-92b2-3b2027c9c4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 480/480 [01:03<00:00,  7.51it/s]\n"
     ]
    }
   ],
   "source": [
    "# Move the model to the appropriate device (e.g., GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "# Create an instance of the same model architecture\n",
    "model = models.resnet18(pretrained=False)\n",
    "num_classes = 10\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "# Load the saved model state dictionary\n",
    "model.load_state_dict(torch.load('/work/scorreacardo_umass_edu/DeepSatGSD/models/trained_model_gsd_resnet18_epochs_3_training_40_perc.pt'))\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "# Define the transformation to be applied to the images\n",
    "transform = torchvision.transforms.Compose([\n",
    "    ToTensor(),\n",
    "    Normalize([0.46619912981987, 0.4138015806674957, 0.2945951819419861], \n",
    "              [0.19115719199180603, 0.1479424238204956, 0.13974712789058685])  #\n",
    "])\n",
    "\n",
    "# Path to the folder containing the images for inference\n",
    "inference_folder = '/work/scorreacardo_umass_edu/DeepSatGSD/data/processed/inference_ts/imgs'\n",
    "inference_folder_mask = '/work/scorreacardo_umass_edu/DeepSatGSD/data/processed/inference_ts/masks'\n",
    "\n",
    "res_counter = []\n",
    "res_dic = {\n",
    "    'img_name': [],\n",
    "    'year': [],\n",
    "    'month': [],\n",
    "    'day': [],\n",
    "    'class_gsd':[],\n",
    "    'iou': [],\n",
    "    'se': [],\n",
    "    'perc_error': [],\n",
    "    'perc_area': []\n",
    "}\n",
    "# Iterate over the images in the inference folder\n",
    "for image_name in tqdm(os.listdir(inference_folder)):\n",
    "    image_path = os.path.join(inference_folder, image_name)\n",
    "    mask_path = os.path.join(inference_folder_mask, image_name)\n",
    "\n",
    "    # Load and preprocess the image\n",
    "    image = np.array(Image.open(image_path)).copy()\n",
    "    mask = np.array(Image.open(mask_path)).copy()\n",
    "    image = image[:, :, :3]\n",
    "    #mask = mask[:, :, :3]\n",
    "    image = transform(image).float()\n",
    "    image = image.unsqueeze(0)  # Add batch dimension\n",
    "    #image = image.to(device, dtype=torch.float32)  # Move the image to GPU\n",
    "    \n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "    _, predicted_class = torch.max(output, 1)\n",
    "    \n",
    "    predicted_class = predicted_class.item()\n",
    "    res_counter.append(predicted_class)\n",
    "    res_dic['img_name'].append(image_name)\n",
    "    res_dic['class_gsd'].append(predicted_class)\n",
    "    res_dic['year'].append(int(image_name.split(\"_\")[0]))\n",
    "    res_dic['month'].append(int(image_name.split(\"_\")[1]))\n",
    "    res_dic['day'].append(int(image_name.split(\"_\")[2]))\n",
    "    \n",
    "    preprocessing_fn = smp.encoders.get_preprocessing_fn(\"resnet34\", \"imagenet\")\n",
    "    seg_model = get_model(class_map[predicted_class].split(\"_\")[1], aug=True)\n",
    "    seg_model.eval()\n",
    "    seg_transform =  albu.Compose([\n",
    "        albu.Lambda(image=preprocessing_fn),\n",
    "        albu.Lambda(image=to_tensor, mask=to_tensor),\n",
    "    ])\n",
    "\n",
    "    image = imread(image_path)[:,:,:3].astype('float32')/255\n",
    "    mask = imread(mask_path, as_gray=True)[:,:,np.newaxis]\n",
    "    \n",
    "    image_transformed = seg_transform(image=image, mask=mask)['image']\n",
    "    mask_transformed = seg_transform(image=image, mask=mask)['mask']\n",
    "    \n",
    "    gt_mask_test = mask_transformed.squeeze()\n",
    "    x_tensor_test = torch.from_numpy(image_transformed).to('cuda').unsqueeze(0)\n",
    "      # Perform inference\n",
    "    with torch.no_grad():\n",
    "        pr_mask_test = seg_model.predict(x_tensor_test)\n",
    "    pr_mask_test = (pr_mask_test.squeeze().cpu().numpy().round())\n",
    "\n",
    "    pr_mask_test_th = sigmoid(pr_mask_test)\n",
    "    pr_mask_test_th = pr_mask_test_th > 0.5\n",
    "    pr_mask_test_th = np.uint8(np.multiply(pr_mask_test_th, 255))\n",
    "\n",
    "    gt_mask_test = np.uint8(gt_mask_test)\n",
    "    #calculating IoU per patch:\n",
    "    iou_score = iou(pr_mask_test_th, gt_mask_test)\n",
    "    se_score = se(pr_mask_test_th, gt_mask_test)\n",
    "    pe_score = perc_error(pr_mask_test_th, gt_mask_test)\n",
    "    pa_score = perc_area(pr_mask_test_th, gt_mask_test)\n",
    "    res_dic['iou'].append(iou_score)\n",
    "    res_dic['se'].append(se_score)\n",
    "    res_dic['perc_error'].append(pe_score)\n",
    "    res_dic['perc_area'].append(pa_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "urbano2",
   "language": "python",
   "name": "urbano2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
